nohup: ignoring input
[Paths]
  IN_DIR : /home/ubuntu/project/identification/output
  OUT_DIR: /home/ubuntu/project/predict/output
  LOG_DIR: /home/ubuntu/project/predict/output/logs
  VERIF  : /home/ubuntu/project/predict/output/verification
  A_MIJ  : /home/ubuntu/project/identification/output/a_mij__sentence_ctx.csv
  SENT   : /home/ubuntu/project/identification/output/sentences_scored_llm_ctx.csv
[JSON]  /home/ubuntu/project/predict/output/logs/selfcheck_inputs.json
[SELF-CHECK][inputs] {'a_mij_company_count': 192, 'sentences_company_count_total': 192, 'sentences_company_count_by_z': {1: 81, 2: 95, 3: 16}, 'companies_intersection': 192, 'companies_union': 192}
[WRITE] /home/ubuntu/project/predict/output/logs/a_mij_clean.csv rows=3528
[WRITE] /home/ubuntu/project/predict/output/logs/s_ijz_pool.csv rows=144
[WRITE] /home/ubuntu/project/predict/output/logs/s_m_ijz_agg.csv rows=34300
[WRITE] /home/ubuntu/project/predict/output/logs/labels_y.csv rows=192
[WRITE] /home/ubuntu/project/predict/output/logs/fijz_logratio.csv rows=144
[WRITE] /home/ubuntu/project/predict/output/logs/features_X_base.csv rows=192
[WRITE] /home/ubuntu/project/predict/output/logs/features_prior.csv rows=192
[WRITE] /home/ubuntu/project/predict/output/logs/features_full.csv rows=192
[JSON]  /home/ubuntu/project/predict/output/logs/split_meta.json
[SPLIT] train=154 companies, val=38 companies
[WRITE] /home/ubuntu/project/predict/output/verification/preds_train_lgbm.csv rows=154
[WRITE] /home/ubuntu/project/predict/output/verification/preds_val_lgbm.csv rows=38
[JSON]  /home/ubuntu/project/predict/output/verification/best_thresholds_lgbm.json
[WRITE] /home/ubuntu/project/predict/output/verification/confusion_matrix_val_lgbm.csv rows=3
/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
/home/ubuntu/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", result.shape[0])
[PLOT]  /home/ubuntu/project/predict/output/confusion_matrix_val_lgbm.png
[PLOT]  /home/ubuntu/project/predict/output/roc_ovr_val_lgbm.png
[PLOT]  /home/ubuntu/project/predict/output/pr_ovr_val_lgbm.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z1_val_lgbm.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z2_val_lgbm.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z3_val_lgbm.png
[PLOT]  /home/ubuntu/project/predict/output/p_true_hist_val_lgbm.png
[PLOT]  /home/ubuntu/project/predict/output/p_true_violin_by_class_val_lgbm.png
[COPY] confusion_matrix_val_lgbm.png -> confusion_matrix_val.png
[COPY] roc_ovr_val_lgbm.png -> roc_ovr_val.png
[COPY] pr_ovr_val_lgbm.png -> pr_ovr_val.png
[COPY] p_true_hist_val_lgbm.png -> p_true_hist_val.png
[COPY] p_true_violin_by_class_val_lgbm.png -> p_true_violin_by_class_val.png
[WRITE] /home/ubuntu/project/predict/output/preds_multinomial.csv rows=192
[JSON]  /home/ubuntu/project/predict/output/verification/metrics_lgbm.json
[JSON]  /home/ubuntu/project/predict/output/logs/selfcheck_inputs_vs_preds.json
[SELF-CHECK][inputs vs preds] {'preds_company_count': 192, 'preds_by_z_star': {1: 82, 2: 95, 3: 15}, 'input_sentences_company_total': 192, 'input_a_mij_company_total': 192}
[WRITE] /home/ubuntu/project/predict/output/verification/preds_train_xgb.csv rows=154
[WRITE] /home/ubuntu/project/predict/output/verification/preds_val_xgb.csv rows=38
[JSON]  /home/ubuntu/project/predict/output/verification/best_thresholds_xgb.json
[WRITE] /home/ubuntu/project/predict/output/verification/confusion_matrix_val_xgb.csv rows=3
[PLOT]  /home/ubuntu/project/predict/output/confusion_matrix_val_xgb.png
[PLOT]  /home/ubuntu/project/predict/output/roc_ovr_val_xgb.png
[PLOT]  /home/ubuntu/project/predict/output/pr_ovr_val_xgb.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z1_val_xgb.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z2_val_xgb.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z3_val_xgb.png
[PLOT]  /home/ubuntu/project/predict/output/p_true_hist_val_xgb.png
[PLOT]  /home/ubuntu/project/predict/output/p_true_violin_by_class_val_xgb.png
[JSON]  /home/ubuntu/project/predict/output/verification/metrics_xgb.json
[JSON]  /home/ubuntu/project/predict/output/verification/metrics_ens.json
[WRITE] /home/ubuntu/project/predict/output/verification/preds_val_ens.csv rows=38
[WRITE] /home/ubuntu/project/predict/output/verification/confusion_matrix_val_ens.csv rows=3
[PLOT]  /home/ubuntu/project/predict/output/confusion_matrix_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/roc_ovr_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/pr_ovr_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z1_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z2_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/calibration_z3_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/p_true_hist_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/p_true_violin_by_class_val_ens.png
[PLOT]  /home/ubuntu/project/predict/output/model_perf_compare.png
[JSON]  /home/ubuntu/project/predict/output/verification/metrics_summary.json

[Done] ✓ logs→output/logs, verification→output/verification, figures→output/
         preds_multinomial.csv → output/  (沿用旧名，默认使用 LGBM 概率)
         model_perf_compare.png → output/  (LGBM / XGB / ENSEMBLE 验证性能对比)
